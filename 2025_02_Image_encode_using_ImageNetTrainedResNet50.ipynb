{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8166b154",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# This code extracts image features using ImageNet-trained ResNet50 \n",
    "# and visualizes them in a two-dimensional space using t-SNE.\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfda002-3869-478d-96cd-69bc488dc78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from openTSNE import TSNE\n",
    "import umap.umap_ as umap\n",
    "import os, glob\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.colors import to_rgba\n",
    "\n",
    "def set_gpu(gpu_id):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(f\"cuda:{gpu_id}\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "gpu_id = 0\n",
    "device = set_gpu(gpu_id)\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a600777-1086-4afd-a27d-614cd0af5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ResNet50\n",
    "\n",
    "model_name = \"resnet50\"  \n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=1000)\n",
    "model = model.to(device)  \n",
    "model.fc = torch.nn.Identity()  \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return self.transform(image), image_path\n",
    "\n",
    "def extract_features_with_batches(image_paths, model, batch_size=128):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    dataset = ImageDataset(image_paths, transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    features = []\n",
    "    filenames = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_paths in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_features = model(batch_images) \n",
    "            features.extend(batch_features.cpu().numpy())\n",
    "            filenames.extend(batch_paths)\n",
    "\n",
    "    return np.array(features), filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf1dd1-634b-4c3c-8167-bff7755943fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = '/PATH/TO/YOUR/IMAGES'\n",
    "image_paths = sorted(glob.glob(d + '/*/*.png'))\n",
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556582f-e87c-4bf0-b73e-657868ffc399",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512 \n",
    "features, filenames = extract_features_with_batches(image_paths, model, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edca4d7-7970-49ac-aea3-2463f81ac633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    perplexity=30,\n",
    "    learning_rate=\"auto\",\n",
    "    n_jobs=-1,  \n",
    "    random_state=42,\n",
    "    metric=\"cosine\",\n",
    ")\n",
    "features_tsne = tsne.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c64627-0962-4135-8fde-807dcf7584df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "output_dir = \"/YOUR/SAVE/DIRECTORY\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(output_dir, \"features.npy\"), features)  \n",
    "np.save(os.path.join(output_dir, \"filenames.npy\"), np.array(filenames)) \n",
    "np.save(os.path.join(output_dir, \"features_tsne.npy\"), features_tsne)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
