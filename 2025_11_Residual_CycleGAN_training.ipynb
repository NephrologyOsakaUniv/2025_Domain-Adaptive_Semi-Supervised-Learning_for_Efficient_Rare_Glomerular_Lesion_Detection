{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9200fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# This code is used for training a residual cycleGAN. \n",
    "# Set the source images for transformation in source_dirs and the images with the target style in target_dir.\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17b938-cb41-48bc-b614-f34a541ec642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import datetime\n",
    "import glob\n",
    "import re\n",
    "import gc\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "SSIM_WINDOW_SIZE = 11\n",
    "MSE_EPSILON = 1e-10\n",
    "\n",
    "GPU_ID = 0 \n",
    "device = torch.device(f\"cuda:{GPU_ID}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1e800-ee0a-48d9-bc77-f378cfbbbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_experiment(base_dir=None):\n",
    "    paths = {\n",
    "        'base': base_dir,\n",
    "        'checkpoints': os.path.join(base_dir, 'checkpoints'),\n",
    "        'results': os.path.join(base_dir, 'results'),\n",
    "        'logs': os.path.join(base_dir, 'logs'),\n",
    "        'samples': os.path.join(base_dir, 'samples')\n",
    "    }\n",
    "    for path in paths.values():\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        print(f\"Created directory: {path}\")\n",
    "    return paths\n",
    "\n",
    "\n",
    "def denormalize_image(x):\n",
    "    return (x + 1) * 0.5\n",
    "\n",
    "def normalize_image(x):\n",
    "    return x * 2 - 1\n",
    "\n",
    "def visualize_samples(real_A, real_B, fake_A=None, fake_B=None, figsize=(15, 5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    images = []\n",
    "    titles = []\n",
    "    \n",
    "    images.extend([denormalize_image(real_A), denormalize_image(real_B)])\n",
    "    titles.extend(['Real A', 'Real B'])\n",
    "       \n",
    "    if fake_A is not None and fake_B is not None:\n",
    "        images.extend([denormalize_image(fake_B), denormalize_image(fake_A)])\n",
    "        titles.extend(['Fake B', 'Fake A'])\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(images, titles)):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().cpu().numpy().transpose(1, 2, 0)\n",
    "        plt.imshow(img)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c14637a-0ba1-4481-941a-33a4c42cca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCalculator:\n",
    "    def __init__(self, window_size=11):\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def compute_ssim(self, img1, img2):\n",
    "        img1 = denormalize_image(img1)\n",
    "        img2 = denormalize_image(img2)\n",
    "        C1 = (0.01 * 1) ** 2\n",
    "        C2 = (0.03 * 1) ** 2\n",
    "        \n",
    "        ssim_value = 0.0\n",
    "        for channel in range(3):  \n",
    "            img1_channel = img1[:, channel:channel+1, :, :]\n",
    "            img2_channel = img2[:, channel:channel+1, :, :]\n",
    "\n",
    "            kernel = torch.ones(1, 1, self.window_size, self.window_size).to(img1.device)\n",
    "            kernel = kernel / (self.window_size ** 2)\n",
    "\n",
    "            mu1 = F.conv2d(img1_channel, kernel, padding=self.window_size//2)\n",
    "            mu2 = F.conv2d(img2_channel, kernel, padding=self.window_size//2)\n",
    "            \n",
    "            mu1_sq = mu1 ** 2\n",
    "            mu2_sq = mu2 ** 2\n",
    "            mu1_mu2 = mu1 * mu2\n",
    "\n",
    "            sigma1_sq = F.conv2d(img1_channel * img1_channel, kernel, padding=self.window_size//2) - mu1_sq\n",
    "            sigma2_sq = F.conv2d(img2_channel * img2_channel, kernel, padding=self.window_size//2) - mu2_sq\n",
    "            sigma12 = F.conv2d(img1_channel * img2_channel, kernel, padding=self.window_size//2) - mu1_mu2\n",
    "            \n",
    "            ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \\\n",
    "                      ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "            \n",
    "            ssim_value += ssim_map.mean()\n",
    "        \n",
    "        return (ssim_value / 3).item()\n",
    "    \n",
    "    def compute_psnr(self, img1, img2):\n",
    "        img1 = denormalize_image(img1)\n",
    "        img2 = denormalize_image(img2)\n",
    "        \n",
    "        mse = F.mse_loss(img1, img2)\n",
    "        if mse < 1e-10:\n",
    "            return float('inf')\n",
    "        return 20 * torch.log10(1.0 / torch.sqrt(mse)).item()\n",
    "    \n",
    "    def compute_mse(self, img1, img2):\n",
    "        img1 = denormalize_image(img1)\n",
    "        img2 = denormalize_image(img2)\n",
    "        return F.mse_loss(img1, img2).item()\n",
    "    \n",
    "    def compute_all_metrics(self, img1, img2):\n",
    "        return {\n",
    "            'ssim': self.compute_ssim(img1, img2),\n",
    "            'psnr': self.compute_psnr(img1, img2),\n",
    "            'mse': self.compute_mse(img1, img2)\n",
    "        }\n",
    "\n",
    "class StainDataset(Dataset):\n",
    "    def __init__(self, source_dir, target_dir, size=640):\n",
    "        super().__init__()\n",
    "        self.source_dir = source_dir\n",
    "        self.target_dir = target_dir\n",
    "        self.size = size\n",
    "        \n",
    "        self.source_images = sorted([\n",
    "            f for f in os.listdir(source_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))\n",
    "        ])\n",
    "        self.target_images = sorted([\n",
    "            f for f in os.listdir(target_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))\n",
    "        ])\n",
    "        \n",
    "        print(f\"Found {len(self.source_images)} source images and {len(self.target_images)} target images\")\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((size, size)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.source_images), len(self.target_images))\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        source_path = os.path.join(self.source_dir, self.source_images[idx])\n",
    "        source_image = Image.open(source_path).convert('RGB')\n",
    "        \n",
    "        target_idx = torch.randint(0, len(self.target_images), (1,)).item()\n",
    "        target_path = os.path.join(self.target_dir, self.target_images[target_idx])\n",
    "        target_image = Image.open(target_path).convert('RGB')\n",
    "        seed = torch.randint(0, 2**32, (1,)).item()\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        source_image = self.transform(source_image)\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        target_image = self.transform(target_image)\n",
    "        \n",
    "        return source_image, target_image\n",
    "\n",
    "\n",
    "\n",
    "def create_dataloaders(source_dir, target_dir, batch_size=4, num_workers=4, \n",
    "                      train_ratio=0.8, image_size=640):\n",
    "    print(f\"Creating dataloaders from {source_dir} and {target_dir}\")\n",
    "\n",
    "    full_dataset = StainDataset(source_dir, target_dir, size=image_size)\n",
    "    dataset_size = len(full_dataset)\n",
    "    print(f\"Total dataset size: {dataset_size}\")\n",
    "\n",
    "    train_size = int(train_ratio * dataset_size)\n",
    "    val_size = dataset_size - train_size\n",
    "    \n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        full_dataset, \n",
    "        [train_size, val_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    print(f\"Training set size: {len(train_dataset)}\")\n",
    "    print(f\"Validation set size: {len(val_dataset)}\")\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c577a165-d62f-4660-9ebc-bc1945351204",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block with Instance Normalization\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "\n",
    "class ResidualCycleGANGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size=640, initial_filters=32):\n",
    "        super(ResidualCycleGANGenerator, self).__init__()\n",
    "        assert input_size % 16 == 0, \"Input size must be divisible by 16\"\n",
    "        \n",
    "        # encoder\n",
    "        self.encoder = nn.ModuleList([\n",
    "            self._make_encoder_block(3, initial_filters),                    # 640 → 320\n",
    "            self._make_encoder_block(initial_filters, initial_filters * 2),    # 320 → 160\n",
    "            self._make_encoder_block(initial_filters * 2, initial_filters * 4),  # 160 → 80\n",
    "            self._make_encoder_block(initial_filters * 4, initial_filters * 8)   # 80 → 40\n",
    "        ])\n",
    "        \n",
    "        # residual block\n",
    "        self.middle = nn.Sequential(\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),  \n",
    "            ResidualBlock(initial_filters * 8),  \n",
    "        )\n",
    "        \n",
    "        # decorder\n",
    "        self.decoder = nn.ModuleList([\n",
    "            self._make_decoder_block(initial_filters * 16, initial_filters * 4),  # 40 → 80\n",
    "            self._make_decoder_block(initial_filters * 8, initial_filters * 2),   # 80 → 160\n",
    "            self._make_decoder_block(initial_filters * 4, initial_filters),       # 160 → 320\n",
    "            self._make_decoder_block(initial_filters * 2, initial_filters)        # 320 → 640\n",
    "        ])\n",
    "        \n",
    "        # Final Output Layer (Difference Map Generation)\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(initial_filters + 3, initial_filters, kernel_size=3),\n",
    "            nn.InstanceNorm2d(initial_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(initial_filters, 3, kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _make_encoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2)  \n",
    "        )\n",
    "\n",
    "    def _make_decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),  \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_features = []\n",
    "        current = x\n",
    "        for encoder in self.encoder:\n",
    "            current = encoder(current)\n",
    "            encoder_features.append(current)\n",
    "        \n",
    "        current = self.middle(current)\n",
    "        current = current + encoder_features[-1]  \n",
    "        \n",
    "        for i, decoder in enumerate(self.decoder):\n",
    "            current = decoder(torch.cat([current, encoder_features[-(i+1)]], dim=1))\n",
    "        \n",
    "        residual = self.final(torch.cat([current, x], dim=1))\n",
    "        \n",
    "        return x + residual\n",
    "\n",
    "\n",
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_channels=3, ndf=64):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            # Layer 1: no normalization\n",
    "            nn.Conv2d(input_channels, ndf, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # Output layer\n",
    "            nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d727af4-a982-4bd4-a448-d195cae39569",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGANTrainer:\n",
    "    def __init__(self, generator_AB, generator_BA, discriminator_A, discriminator_B,\n",
    "                 device, checkpoint_dir, lr=0.0001, beta1=0.5, beta2=0.999, \n",
    "                 lambda_cycle=10.0, lambda_identity=0.5, lambda_residual=0.2):\n",
    "        self.device = device\n",
    "        self.checkpoint_dir = checkpoint_dir  \n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        self.lambda_identity = lambda_identity\n",
    "        self.lambda_residual = lambda_residual  \n",
    "        self.gen_AB = generator_AB.to(device)\n",
    "        self.gen_BA = generator_BA.to(device)\n",
    "        self.disc_A = discriminator_A.to(device)\n",
    "        self.disc_B = discriminator_B.to(device)\n",
    "        \n",
    "        self.optimizer_G = torch.optim.Adam(\n",
    "            list(generator_AB.parameters()) + list(generator_BA.parameters()),\n",
    "            lr=lr, betas=(beta1, beta2)\n",
    "        )\n",
    "        self.optimizer_D = torch.optim.Adam(\n",
    "            list(discriminator_A.parameters()) + list(discriminator_B.parameters()),\n",
    "            lr=lr, betas=(beta1, beta2)\n",
    "        )\n",
    "        \n",
    "        self.scheduler_G = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer_G,\n",
    "            mode='max',  \n",
    "            factor=0.5,  \n",
    "            patience=5,  \n",
    "            verbose=True,\n",
    "            min_lr=1e-6  \n",
    "        )\n",
    "\n",
    "        self.scheduler_D = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer_D,\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=True,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.lambda_cycle = lambda_cycle\n",
    "        self.metrics_calculator = MetricsCalculator()\n",
    "        \n",
    "        self.loss_history = {\n",
    "            'G_loss': [], 'D_loss': [],\n",
    "            'cycle_loss': [], 'metrics': []\n",
    "        }\n",
    "    \n",
    "    def compute_cycle_loss(self, real_image, cycled_image):\n",
    "        pixel_wise_loss = F.l1_loss(cycled_image, real_image, reduction='none')\n",
    "        flat_loss = pixel_wise_loss.view(pixel_wise_loss.size(0), -1)\n",
    "        threshold = torch.quantile(flat_loss, 0.9, dim=1, keepdim=True)\n",
    "        mask = (flat_loss > threshold).float()\n",
    "        return (flat_loss * mask).mean()\n",
    "\n",
    "\n",
    "    def train_step(self, real_A, real_B):\n",
    "        batch_size = real_A.size(0)\n",
    "    \n",
    "        fake_B = self.gen_AB(real_A)\n",
    "        fake_A = self.gen_BA(real_B)\n",
    "        cycle_A = self.gen_BA(fake_B)\n",
    "        cycle_B = self.gen_AB(fake_A)\n",
    "        \n",
    "        self.optimizer_G.zero_grad()\n",
    "        \n",
    "        fake_A_disc = self.disc_A(fake_A)\n",
    "        fake_B_disc = self.disc_B(fake_B)\n",
    "        real_label = torch.ones_like(fake_A_disc).to(self.device)\n",
    "        \n",
    "        g_loss_A = F.mse_loss(fake_A_disc, real_label)\n",
    "        g_loss_B = F.mse_loss(fake_B_disc, real_label)\n",
    "        g_loss_adv = g_loss_A + g_loss_B\n",
    "        \n",
    "        cycle_loss_A = self.compute_cycle_loss(real_A, cycle_A)\n",
    "        cycle_loss_B = self.compute_cycle_loss(real_B, cycle_B)\n",
    "        cycle_loss = (cycle_loss_A + cycle_loss_B) * self.lambda_cycle\n",
    "        \n",
    "        identity_A = self.gen_BA(real_A)\n",
    "        identity_B = self.gen_AB(real_B)\n",
    "        identity_loss = (\n",
    "            F.l1_loss(identity_A, real_A) +\n",
    "            F.l1_loss(identity_B, real_B)\n",
    "        ) * self.lambda_identity\n",
    "\n",
    "        residual_map_in_A_domain = fake_A - real_A\n",
    "        residual_map_in_B_domain = fake_B - real_B\n",
    "        residual_loss = self.lambda_residual * (\n",
    "            torch.mean(torch.abs(residual_map_in_A_domain)) +\n",
    "            torch.mean(torch.abs(residual_map_in_B_domain))\n",
    "        )\n",
    "\n",
    "        g_loss = g_loss_adv + cycle_loss + identity_loss + residual_loss\n",
    "        g_loss.backward()\n",
    "        self.optimizer_G.step()\n",
    "        \n",
    "        self.optimizer_D.zero_grad()\n",
    "    \n",
    "        d_real_A = self.disc_A(real_A)\n",
    "        d_real_B = self.disc_B(real_B)\n",
    "        d_fake_A = self.disc_A(fake_A.detach())\n",
    "        d_fake_B = self.disc_B(fake_B.detach())\n",
    "        \n",
    "        d_loss = (\n",
    "            F.mse_loss(d_real_A, torch.ones_like(d_real_A)) +\n",
    "            F.mse_loss(d_real_B, torch.ones_like(d_real_B)) +\n",
    "            F.mse_loss(d_fake_A, torch.zeros_like(d_fake_A)) +\n",
    "            F.mse_loss(d_fake_B, torch.zeros_like(d_fake_B))\n",
    "        ) * 0.5\n",
    "        \n",
    "        d_loss.backward()\n",
    "        self.optimizer_D.step()\n",
    "\n",
    "        return {\n",
    "            'g_loss': g_loss.item(),\n",
    "            'd_loss': d_loss.item(),\n",
    "            'cycle_loss': cycle_loss.item(),  \n",
    "            'identity_loss': identity_loss.item(),\n",
    "            'residual_loss': residual_loss.item(),\n",
    "            'fake_A': fake_A,\n",
    "            'fake_B': fake_B\n",
    "        }\n",
    "\n",
    "\n",
    "    def validate(self, val_loader):\n",
    "        self.gen_AB.eval()\n",
    "        self.gen_BA.eval()\n",
    "        \n",
    "        metrics_sum = {\n",
    "            'direct_ssim': 0.0, 'direct_psnr': 0.0, 'direct_mse': 0.0,\n",
    "            'cycle_ssim': 0.0, 'cycle_psnr': 0.0, 'cycle_mse': 0.0,\n",
    "            'combined_ssim': 0.0, 'combined_psnr': 0.0, 'combined_mse': 0.0\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for real_A, real_B in val_loader:\n",
    "                real_A = real_A.to(self.device)\n",
    "                real_B = real_B.to(self.device)\n",
    "                \n",
    "                fake_B = self.gen_AB(real_A)\n",
    "                fake_A = self.gen_BA(real_B)\n",
    "                \n",
    "                cycle_A = self.gen_BA(fake_B)\n",
    "                cycle_B = self.gen_AB(fake_A)\n",
    "                \n",
    "                metrics_AB = self.metrics_calculator.compute_all_metrics(fake_B, real_B)\n",
    "                metrics_BA = self.metrics_calculator.compute_all_metrics(fake_A, real_A)\n",
    "                \n",
    "                metrics_cycle_A = self.metrics_calculator.compute_all_metrics(cycle_A, real_A)\n",
    "                metrics_cycle_B = self.metrics_calculator.compute_all_metrics(cycle_B, real_B)\n",
    "                \n",
    "                for key in ['ssim', 'psnr', 'mse']:\n",
    "                    metrics_sum[f'direct_{key}'] += (metrics_AB[key] + metrics_BA[key]) / 2\n",
    "            \n",
    "                for key in ['ssim', 'psnr', 'mse']:\n",
    "                    metrics_sum[f'cycle_{key}'] += (metrics_cycle_A[key] + metrics_cycle_B[key]) / 2\n",
    "                \n",
    "                for key in ['ssim', 'psnr', 'mse']:\n",
    "                    direct_val = (metrics_AB[key] + metrics_BA[key]) / 2\n",
    "                    cycle_val = (metrics_cycle_A[key] + metrics_cycle_B[key]) / 2\n",
    "                    metrics_sum[f'combined_{key}'] += (direct_val + cycle_val) / 2\n",
    "        \n",
    "        num_batches = len(val_loader)\n",
    "        avg_metrics = {k: v / num_batches for k, v in metrics_sum.items()}\n",
    "        \n",
    "        self.gen_AB.train()\n",
    "        self.gen_BA.train()\n",
    "        \n",
    "        return avg_metrics\n",
    "\n",
    "\n",
    "\n",
    "    def save_checkpoint(self, epoch, metrics, is_best=False):\n",
    "        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'generator_AB': self.gen_AB.state_dict(),\n",
    "            'generator_BA': self.gen_BA.state_dict(),\n",
    "            'discriminator_A': self.disc_A.state_dict(),\n",
    "            'discriminator_B': self.disc_B.state_dict(),\n",
    "            'optimizer_G': self.optimizer_G.state_dict(),\n",
    "            'optimizer_D': self.optimizer_D.state_dict(),\n",
    "            'scheduler_G': self.scheduler_G.state_dict(),\n",
    "            'scheduler_D': self.scheduler_D.state_dict(),\n",
    "            'metrics': metrics,\n",
    "            'loss_history': self.loss_history\n",
    "        }\n",
    "        \n",
    "        prefix = 'best' if is_best else f'epoch_{epoch}'\n",
    "        save_path = os.path.join(\n",
    "            self.checkpoint_dir,\n",
    "            f'{prefix}_model_combined_ssim_{metrics[\"combined_ssim\"]:.4f}_direct_{metrics[\"direct_ssim\"]:.4f}_cycle_{metrics[\"cycle_ssim\"]:.4f}_{timestamp}.pth'\n",
    "        )\n",
    "        torch.save(checkpoint, save_path)\n",
    "        print(f\"Saved checkpoint: {save_path}\")\n",
    "\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  \n",
    "\n",
    "\n",
    "\n",
    "def train(trainer, train_loader, val_loader, num_epochs, save_dir, save_interval=5):\n",
    "    best_combined_ssim = -float('inf')\n",
    "    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = {'g_loss': 0., 'd_loss': 0., 'cycle_loss': 0.}\n",
    "        num_batches = len(train_loader)\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for i, (real_A, real_B) in enumerate(pbar):\n",
    "            real_A = real_A.to(trainer.device)\n",
    "            real_B = real_B.to(trainer.device)\n",
    "            \n",
    "            losses = trainer.train_step(real_A, real_B)\n",
    "            \n",
    "            for key in ['g_loss', 'd_loss', 'cycle_loss']:\n",
    "                epoch_losses[key] += losses[key]\n",
    "            \n",
    "            current_losses = {\n",
    "                key: value / (i + 1) \n",
    "                for key, value in epoch_losses.items()\n",
    "            }\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'G_loss': f\"{current_losses['g_loss']:.4f}\",\n",
    "                'D_loss': f\"{current_losses['d_loss']:.4f}\",\n",
    "                'Cycle_loss': f\"{current_losses['cycle_loss']:.4f}\"\n",
    "            })\n",
    "        \n",
    "        avg_losses = {key: value / num_batches for key, value in epoch_losses.items()}\n",
    "        \n",
    "        metrics = trainer.validate(val_loader)\n",
    "        \n",
    "        early_stopping(-metrics['combined_ssim'])  \n",
    "        if early_stopping.early_stop:\n",
    "            print(f\"Early stopping triggered at epoch {epoch}\")\n",
    "            break        \n",
    "            \n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            save_validation_images(trainer, val_loader, save_dir, epoch)\n",
    "        \n",
    "        if metrics['combined_ssim'] > best_combined_ssim:\n",
    "            best_combined_ssim = metrics['combined_ssim']\n",
    "            trainer.save_checkpoint(epoch, metrics, is_best=True)\n",
    "        \n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            trainer.save_checkpoint(epoch, metrics)\n",
    "        \n",
    "        if isinstance(trainer.scheduler_G, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            trainer.scheduler_G.step(metrics['combined_ssim'])\n",
    "            trainer.scheduler_D.step(metrics['combined_ssim'])\n",
    "        else:\n",
    "            trainer.scheduler_G.step()\n",
    "            trainer.scheduler_D.step()\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1} Results:\")\n",
    "        print(\"Training Losses:\")\n",
    "        print(f\"  Generator Loss: {avg_losses['g_loss']:.4f}\")\n",
    "        print(f\"  Discriminator Loss: {avg_losses['d_loss']:.4f}\")\n",
    "        print(f\"  Cycle Loss: {avg_losses['cycle_loss']:.4f}\")\n",
    "        print(\"\\nValidation Metrics:\")\n",
    "        print(\"Direct Translation Quality:\")\n",
    "        print(f\"  SSIM: {metrics['direct_ssim']:.4f}\")\n",
    "        print(f\"  PSNR: {metrics['direct_psnr']:.4f}\")\n",
    "        print(f\"  MSE: {metrics['direct_mse']:.4f}\")\n",
    "        print(\"\\nCycle Consistency Quality:\")\n",
    "        print(f\"  SSIM: {metrics['cycle_ssim']:.4f}\")\n",
    "        print(f\"  PSNR: {metrics['cycle_psnr']:.4f}\")\n",
    "        print(f\"  MSE: {metrics['cycle_mse']:.4f}\")\n",
    "        print(\"\\nCombined Metrics (Direct + Cycle):\")\n",
    "        print(f\"  SSIM: {metrics['combined_ssim']:.4f}\")\n",
    "        print(f\"  PSNR: {metrics['combined_psnr']:.4f}\")\n",
    "        print(f\"  MSE: {metrics['combined_mse']:.4f}\\n\")\n",
    "\n",
    "\n",
    "def save_validation_images(trainer, val_loader,save_dir, epoch):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    trainer.gen_AB.eval()\n",
    "    trainer.gen_BA.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        real_A, real_B = next(iter(val_loader))\n",
    "        real_A = real_A.to(trainer.device)\n",
    "        real_B = real_B.to(trainer.device)\n",
    "        \n",
    "        fake_B = trainer.gen_AB(real_A)\n",
    "        fake_A = trainer.gen_BA(real_B)\n",
    "        \n",
    "        image_grid = torch.cat([\n",
    "            real_A[0:1], fake_B[0:1], real_B[0:1],\n",
    "            real_B[0:1], fake_A[0:1], real_A[0:1]\n",
    "        ], dim=3)\n",
    "        \n",
    "        save_path = os.path.join(save_dir, f'epoch_{epoch+1}.png')\n",
    "        save_image(\n",
    "            denormalize_image(image_grid),\n",
    "            save_path\n",
    "        )\n",
    "        print(f\"Validation images saved to: {save_path}\")\n",
    "    \n",
    "    trainer.gen_AB.train()\n",
    "    trainer.gen_BA.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9782a579-8317-4fda-8a4e-cf51de9ec27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_config = {\n",
    "    'target_dir': '/PATH/TO/YOUR/TAEGET/DIRECTORY',\n",
    "    'batch_size': 4,\n",
    "    'epochs': 100,\n",
    "    'lr': 0.0001,\n",
    "    'lambda_cycle': 5.0,\n",
    "    'image_size': 640,\n",
    "    'num_workers': 8,\n",
    "    'save_interval': 5,\n",
    "    'resume_from': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad43257-9a65-46c6-a2a3-88e460cb2092",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dirs = [\n",
    "    '/PATH/TO/YOUR/SOURCE/DIRECTORY'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b513b583-6615-45cc-9e2a-2df71d015374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_sources(source_dirs, base_config):\n",
    "    for source_dir in source_dirs:\n",
    "        source_name = os.path.basename(source_dir)\n",
    "        exp_name = f'residual_cyclegan_{source_name}toHGO_C10_I05_R02'\n",
    "        \n",
    "        config = deepcopy(base_config)\n",
    "        config['source_dir'] = source_dir\n",
    "        config['exp_name'] = exp_name\n",
    "        \n",
    "        print(f\"\\nStarting training for source: {source_dir}\")\n",
    "        print(f\"Experiment name: {exp_name}\")\n",
    "        \n",
    "        try:\n",
    "            paths = setup_experiment(config['exp_name'])\n",
    "\n",
    "            train_loader, val_loader = create_dataloaders(\n",
    "                source_dir=config['source_dir'],\n",
    "                target_dir=config['target_dir'],\n",
    "                batch_size=config['batch_size'],\n",
    "                num_workers=config['num_workers'],\n",
    "                image_size=config['image_size']\n",
    "            )\n",
    "\n",
    "            generator_AB = ResidualCycleGANGenerator(input_size=config['image_size']).to(device)\n",
    "            generator_BA = ResidualCycleGANGenerator(input_size=config['image_size']).to(device)\n",
    "            discriminator_A = PatchGANDiscriminator().to(device)\n",
    "            discriminator_B = PatchGANDiscriminator().to(device)\n",
    "\n",
    "            trainer = CycleGANTrainer(\n",
    "                generator_AB=generator_AB,\n",
    "                generator_BA=generator_BA,\n",
    "                discriminator_A=discriminator_A,\n",
    "                discriminator_B=discriminator_B,\n",
    "                device=device,\n",
    "                checkpoint_dir=paths['checkpoints'],\n",
    "                lr=config['lr'],\n",
    "                lambda_cycle=10.0,\n",
    "                lambda_identity=0.5,\n",
    "                lambda_residual=0.2\n",
    "            )\n",
    "\n",
    "            train(\n",
    "                trainer=trainer,\n",
    "                train_loader=train_loader,\n",
    "                val_loader=val_loader,\n",
    "                num_epochs=config['epochs'],\n",
    "                save_interval=config['save_interval'],\n",
    "                save_dir=os.path.join('.', exp_name, 'results')\n",
    "            )\n",
    "            \n",
    "            final_path = os.path.join(paths['checkpoints'], 'final_model.pth')\n",
    "            torch.save({\n",
    "                'generator_AB': generator_AB.state_dict(),\n",
    "                'generator_BA': generator_BA.state_dict(),\n",
    "                'discriminator_A': discriminator_A.state_dict(),\n",
    "                'discriminator_B': discriminator_B.state_dict(),\n",
    "            }, final_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during training for {source_dir}: {str(e)}\")\n",
    "            \n",
    "        finally:\n",
    "            if 'trainer' in locals():\n",
    "                del trainer\n",
    "            if 'generator_AB' in locals():\n",
    "                del generator_AB\n",
    "            if 'generator_BA' in locals():\n",
    "                del generator_BA\n",
    "            if 'discriminator_A' in locals():\n",
    "                del discriminator_A\n",
    "            if 'discriminator_B' in locals():\n",
    "                del discriminator_B\n",
    "            if 'train_loader' in locals():\n",
    "                del train_loader\n",
    "            if 'val_loader' in locals():\n",
    "                del val_loader\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            print(f\"\\nCompleted training for source: {source_dir}\")\n",
    "            print(\"Memory cleaned up and ready for next model\")\n",
    "            \n",
    "            if os.path.exists('./__pycache__'):\n",
    "                shutil.rmtree('./__pycache__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1083d0b2-298c-4211-a593-57d560c17ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_multiple_sources(source_dirs, base_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
