{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b52f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# This code is used for image style transfer using a pre-trained residual CycleGAN.\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16486d32-f13b-4324-9544-8cb9846309a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from torchvision.utils import save_image\n",
    "import glob\n",
    "\n",
    "GPU_ID = 0 \n",
    "device = torch.device(f\"cuda:{GPU_ID}\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "GPU_ID2 = 'cuda:' + str(GPU_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842b15d-f8eb-40ec-af59-e34f152d4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SimpleImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, size=640):\n",
    "        self.image_dir = image_dir\n",
    "        self.size = size\n",
    "        \n",
    "        self.images = sorted([\n",
    "            f for f in os.listdir(image_dir)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))\n",
    "        ])\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((size, size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return {\n",
    "            'image': self.transform(image),\n",
    "            'path': self.images[idx]\n",
    "        }\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual Block with Instance Normalization\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(channels, channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResidualCycleGANGenerator(nn.Module):\n",
    "    def __init__(self, input_size=640, initial_filters=32):\n",
    "        super(ResidualCycleGANGenerator, self).__init__()\n",
    "        assert input_size % 16 == 0, \"Input size must be divisible by 16\"\n",
    "\n",
    "        self.encoder = nn.ModuleList([\n",
    "            self._make_encoder_block(3, initial_filters),                    # 640 → 320\n",
    "            self._make_encoder_block(initial_filters, initial_filters * 2),    # 320 → 160\n",
    "            self._make_encoder_block(initial_filters * 2, initial_filters * 4),  # 160 → 80\n",
    "            self._make_encoder_block(initial_filters * 4, initial_filters * 8)   # 80 → 40\n",
    "        ])\n",
    "        \n",
    "        self.middle = nn.Sequential(\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "            ResidualBlock(initial_filters * 8),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.ModuleList([\n",
    "            self._make_decoder_block(initial_filters * 16, initial_filters * 4),  # 40 → 80\n",
    "            self._make_decoder_block(initial_filters * 8, initial_filters * 2),   # 80 → 160\n",
    "            self._make_decoder_block(initial_filters * 4, initial_filters),       # 160 → 320\n",
    "            self._make_decoder_block(initial_filters * 2, initial_filters)        # 320 → 640\n",
    "        ])\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(initial_filters + 3, initial_filters, kernel_size=3),\n",
    "            nn.InstanceNorm2d(initial_filters),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(initial_filters, 3, kernel_size=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def _make_encoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "    def _make_decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_features = []\n",
    "        current = x\n",
    "        for encoder in self.encoder:\n",
    "            current = encoder(current)\n",
    "            encoder_features.append(current)\n",
    "        \n",
    "        current = self.middle(current)\n",
    "        current = current + encoder_features[-1]\n",
    "        \n",
    "        for i, decoder in enumerate(self.decoder):\n",
    "            current = decoder(torch.cat([current, encoder_features[-(i+1)]], dim=1))\n",
    "\n",
    "        residual = self.final(torch.cat([current, x], dim=1))\n",
    "        \n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eda31d-a5ba-4460-aa85-a4fd13c7cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PTHFileProcessor:\n",
    "    def __init__(self, pth_dir):\n",
    "        self.pth_dir = pth_dir\n",
    "        self.pattern = r'_source_([A-Z]{3}).*to([A-Z]{3})_'\n",
    "\n",
    "    def validate_pth_files(self):\n",
    "        pth_files = [f for f in os.listdir(self.pth_dir) if f.endswith('.pth')]\n",
    "        if not pth_files:\n",
    "            raise ValueError(f\"No PTH files found in {self.pth_dir}\")\n",
    "\n",
    "        source_institutes = set()\n",
    "        valid_files = []\n",
    "\n",
    "        for pth_file in pth_files:\n",
    "            match = re.search(self.pattern, pth_file)\n",
    "            if match:\n",
    "                source_inst = match.group(1)\n",
    "                source_institutes.add(source_inst)\n",
    "                valid_files.append({\n",
    "                    'file': pth_file,\n",
    "                    'source': source_inst,\n",
    "                    'target': match.group(2)\n",
    "                })\n",
    "\n",
    "        if len(source_institutes) != 1:\n",
    "            raise ValueError(f\"Found multiple or no source institutes: {source_institutes}\")\n",
    "\n",
    "        return valid_files, source_institutes.pop()\n",
    "\n",
    "class SimpleImageDataset(Dataset):\n",
    "    def __init__(self, image_paths, size=640):\n",
    "        self.image_paths = image_paths\n",
    "        self.size = size\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((size, size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return {\n",
    "            'image': self.transform(image),\n",
    "            'path': image_path\n",
    "        }\n",
    "\n",
    "def denormalize_image(x):\n",
    "    return (x + 1) * 0.5\n",
    "\n",
    "class ImageConverter:\n",
    "    def __init__(self, device=GPU_ID2):\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        if self.model is not None:\n",
    "            del self.model\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        self.model = ResidualCycleGANGenerator(input_size=640).to(self.device)\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        if 'generator_AB' in checkpoint:\n",
    "            state_dict = checkpoint['generator_AB']\n",
    "        else:\n",
    "            state_dict = checkpoint\n",
    "        \n",
    "        self.model.load_state_dict(state_dict)\n",
    "        self.model.eval()\n",
    "\n",
    "    def convert_images(self, image_paths, output_paths, batch_size=32):\n",
    "        dataset = SimpleImageDataset(image_paths)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, \n",
    "                              shuffle=False, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        print(\"\\nChecking paths before conversion:\")\n",
    "        for in_path, out_path in zip(image_paths[:5], output_paths[:5]):\n",
    "            print(f\"Input: {in_path}\")\n",
    "            print(f\"Output: {out_path}\")\n",
    "            print(\"-\" * 80)\n",
    "        \n",
    "        batch_count = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=\"Converting images\"):\n",
    "                images = batch['image'].to(self.device)\n",
    "                paths = batch['path']\n",
    "\n",
    "                start_idx = batch_count * batch_size\n",
    "                end_idx = start_idx + len(images)\n",
    "                current_output_paths = output_paths[start_idx:end_idx]\n",
    "                \n",
    "                print(f\"\\nProcessing batch {batch_count}:\")\n",
    "                converted_images = self.model(images)\n",
    "\n",
    "                for idx, (img, in_path, out_path) in enumerate(zip(converted_images, paths, current_output_paths)):\n",
    "                    print(f\"Saving image {start_idx + idx}:\")\n",
    "                    print(f\"From: {in_path}\")\n",
    "                    print(f\"To: {out_path}\")\n",
    "\n",
    "                    out_dir = os.path.dirname(out_path)\n",
    "                    if not os.path.exists(out_dir):\n",
    "                        print(f\"Creating directory: {out_dir}\")\n",
    "                        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "                    save_image(denormalize_image(img), out_path)\n",
    "                    print(f\"Saved successfully\")\n",
    "                    print(\"-\" * 40)\n",
    "                \n",
    "                batch_count += 1\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    print(f\"GPU Memory allocated: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "                    print(f\"GPU Memory cached: {torch.cuda.memory_cached() / 1024**2:.2f} MB\")\n",
    "\n",
    "def process_directory(input_dir, output_dir, pth_dir, batch_size=32):\n",
    "    pth_processor = PTHFileProcessor(pth_dir)\n",
    "    valid_pth_files, source_institute = pth_processor.validate_pth_files()\n",
    "    print(f\"Found {len(valid_pth_files)} valid PTH files for source institute {source_institute}\")\n",
    "    print(\"\\nValid PTH files:\")\n",
    "    for pth_info in valid_pth_files:\n",
    "        print(f\"- {pth_info['file']}\")\n",
    "        print(f\"  Source: {pth_info['source']}\")\n",
    "        print(f\"  Target: {pth_info['target']}\")\n",
    "\n",
    "    image_pattern = os.path.join(input_dir, \"*\", \"woAug\", \"*\", \"img\", \"*.png\")\n",
    "    all_image_paths = glob.glob(image_pattern)\n",
    "    print(f\"\\nFound {len(all_image_paths)} total image paths\")\n",
    "\n",
    "    valid_images = []\n",
    "    for img_path in all_image_paths:\n",
    "        parts = Path(img_path).parts\n",
    "        for part in parts:\n",
    "            if source_institute in part:\n",
    "                valid_images.append(img_path)\n",
    "                break\n",
    "    \n",
    "    print(f\"\\nFiltered to {len(valid_images)} valid images\")\n",
    "    print(\"\\nExample valid image paths:\")\n",
    "    for path in valid_images[:5]:\n",
    "        print(f\"- {path}\")\n",
    "\n",
    "    converter = ImageConverter(device=device)\n",
    "    \n",
    "    for pth_index, pth_info in enumerate(valid_pth_files):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Processing PTH file {pth_index + 1}/{len(valid_pth_files)}: {pth_info['file']}\")\n",
    "        suffix = f\"_{pth_info['source']}2{pth_info['target']}\"\n",
    "\n",
    "        current_output_paths = []\n",
    "        current_input_label_paths = []\n",
    "        current_output_label_paths = []\n",
    "        \n",
    "        print(\"\\nGenerating output paths...\")\n",
    "        for img_path in valid_images:\n",
    "            rel_path = os.path.relpath(img_path, input_dir)\n",
    "            out_dir = os.path.join(output_dir, os.path.dirname(rel_path))\n",
    "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            new_name = f\"{base_name}{suffix}.png\"\n",
    "            output_path = os.path.join(out_dir, new_name)\n",
    "            current_output_paths.append(output_path)\n",
    "\n",
    "            label_path = img_path.replace('/img/', '/lab/').replace('.png', '.txt')\n",
    "            if os.path.exists(label_path):\n",
    "                output_label_path = output_path.replace('/img/', '/lab/').replace('.png', '.txt')\n",
    "                current_input_label_paths.append(label_path)\n",
    "                current_output_label_paths.append(output_label_path)\n",
    "\n",
    "            if len(current_output_paths) <= 5:\n",
    "                print(f\"\\nInput image: {img_path}\")\n",
    "                print(f\"Output image: {output_path}\")\n",
    "                if os.path.exists(label_path):\n",
    "                    print(f\"Input label: {label_path}\")\n",
    "                    print(f\"Output label: {output_label_path}\")\n",
    "\n",
    "        print(f\"\\nGenerated {len(current_output_paths)} output paths\")\n",
    "        print(f\"Found {len(current_input_label_paths)} label files\")\n",
    "\n",
    "        print(f\"\\nLoading model: {pth_info['file']}\")\n",
    "        converter.load_model(os.path.join(pth_dir, pth_info['file']))\n",
    "\n",
    "        print(f\"Model device: {next(converter.model.parameters()).device}\")\n",
    "        \n",
    "        print(\"\\nStarting image conversion...\")\n",
    "        converter.convert_images(valid_images, current_output_paths, batch_size=batch_size)\n",
    "\n",
    "        print(\"\\nCopying label files...\")\n",
    "        for in_label, out_label in zip(current_input_label_paths, current_output_label_paths):\n",
    "            out_dir = os.path.dirname(out_label)\n",
    "            if not os.path.exists(out_dir):\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "            try:\n",
    "                shutil.copy2(in_label, out_label)\n",
    "                if out_label in current_output_label_paths[:5]:\n",
    "                    print(f\"Copied: {in_label} -> {out_label}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error copying label file {in_label}: {str(e)}\")\n",
    "\n",
    "        print(f\"\\nCompleted processing with {pth_info['file']}\")\n",
    "        print(f\"Converted {len(current_output_paths)} images\")\n",
    "        print(f\"Copied {len(current_output_label_paths)} label files\")\n",
    "\n",
    "        del current_output_paths\n",
    "        del current_input_label_paths\n",
    "        del current_output_label_paths\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"GPU Memory allocated: {torch.cuda.memory_allocated(GPU_ID) / 1024**2:.2f} MB\")\n",
    "            print(f\"GPU Memory cached: {torch.cuda.memory_cached(GPU_ID) / 1024**2:.2f} MB\")\n",
    "\n",
    "def debug_conversion(input_dir, output_dir, pth_dir, batch_size=32):  \n",
    "    print(\"Starting debug conversion process...\")\n",
    "    print(f\"Input directory: {input_dir}\")\n",
    "    print(f\"Output directory: {output_dir}\")\n",
    "    print(f\"PTH directory: {pth_dir}\")\n",
    "    print(f\"Batch size: {batch_size}\")\n",
    "    \n",
    "    try:\n",
    "        process_directory(input_dir, output_dir, pth_dir, batch_size=batch_size) \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError occurred: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65037139-ecff-434d-807e-41578b85a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/PATH/TO/YOUR/INPUT\"  \n",
    "output_dir = \"/PATH/TO/YOUR/PUTPUT\"  \n",
    "pth_dir = \"/PATH/TO/YOUR/PTH_FILE/DIRECTORY\"  \n",
    "\n",
    "debug_conversion(input_dir, output_dir, pth_dir, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56facf9-50d5-4b5c-93ce-fc5736194294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The input directory must contain a subdirectory called 'woAug'\n",
    "#Images are stored in the 'img' folder, and labels are stored in the 'lab' folder\n",
    "#PTH filenames must contain the patterns sourceXXX and toYYY_ (where XXX and YYY are 3-character institution codes)\n",
    "#The folder names to be processed in the input directory must contain the 3 characters after source_ from the PTH file\n",
    "#The output directory maintains the same structure as the input, with source and destination information added to the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea590185-3cfb-4e8d-afb8-1354d794453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_dir/\n",
    "├── DIR1/\n",
    "│   └── woAug/\n",
    "│       └── XXX_/\n",
    "│           ├── img/\n",
    "│           │   ├── image001.png\n",
    "│           │   ├── image002.png\n",
    "│           │   └── ...\n",
    "│           └── lab/\n",
    "│               ├── image001.txt\n",
    "│               ├── image002.txt\n",
    "│               └── ...\n",
    "├── DIR2/\n",
    "│   └── woAug/\n",
    "│       └── YYY_/\n",
    "│           ├── img/\n",
    "│           │   └── ...\n",
    "│           └── lab/\n",
    "│               └── ...\n",
    "└── ...\n",
    "    \n",
    "\n",
    "pth_dir/\n",
    "├── abc_best_model....pth\n",
    "├── def_best_model....pth\n",
    "└── ...\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
